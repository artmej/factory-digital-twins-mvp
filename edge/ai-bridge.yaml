apiVersion: v1
kind: ConfigMap
metadata:
  name: ai-bridge-config
  namespace: arc
data:
  config.json: |
    {
      "sources": {
        "mqtt": {
          "broker": "mqtt-broker:1883",
          "topics": ["dt/+/telemetry"]
        },
        "postgres": {
          "host": "postgres-smartfactory",
          "port": 5432,
          "database": "smartfactory",
          "user": "sfadmin",
          "password": "SmartFactory2024!"
        }
      },
      "ai": {
        "functionUrl": "https://smartfactory-ai-func-prod.azurewebsites.net",
        "eventHubConnection": "${EVENT_HUB_CONNECTION}",
        "batchSize": 10,
        "intervalMs": 30000
      },
      "filters": {
        "anomalyThreshold": 0.8,
        "criticalSensors": ["factory-main", "line1-main", "machine1"],
        "enablePredictive": true
      }
    }
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-bridge
  namespace: arc
  labels:
    app: ai-bridge
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ai-bridge
  template:
    metadata:
      labels:
        app: ai-bridge
    spec:
      containers:
      - name: ai-bridge
        image: node:18-alpine
        env:
        - name: NODE_ENV
          value: "production"
        volumeMounts:
        - name: config
          mountPath: /app/config
        - name: app-code
          mountPath: /app
        command: ["/bin/sh"]
        args: ["-c", "cd /app && npm install && node bridge.js"]
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
      volumes:
      - name: config
        configMap:
          name: ai-bridge-config
      - name: app-code
        configMap:
          name: ai-bridge-code
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ai-bridge-code
  namespace: arc
data:
  package.json: |
    {
      "name": "smart-factory-ai-bridge",
      "version": "1.0.0",
      "description": "Bridge between edge stack and Azure AI services",
      "main": "bridge.js",
      "dependencies": {
        "mqtt": "^5.3.4",
        "pg": "^8.11.3",
        "@azure/event-hubs": "^5.12.0",
        "axios": "^1.6.5",
        "moment": "^2.30.1"
      }
    }
  bridge.js: |
    const mqtt = require('mqtt');
    const { Client } = require('pg');
    const { EventHubProducerClient } = require('@azure/event-hubs');
    const axios = require('axios');
    const fs = require('fs');
    const moment = require('moment');

    console.log('ðŸŒ‰ Smart Factory AI Bridge starting...');

    // Load configuration
    const config = JSON.parse(fs.readFileSync('/app/config/config.json', 'utf8'));
    console.log('ðŸ“‹ Configuration loaded:', {
      mqttBroker: config.sources.mqtt.broker,
      pgHost: config.sources.postgres.host,
      batchSize: config.ai.batchSize
    });

    // State management
    let messageBatch = [];
    let lastProcessTime = Date.now();

    // MQTT Client
    const mqttClient = mqtt.connect(`mqtt://${config.sources.mqtt.broker}`);

    mqttClient.on('connect', () => {
      console.log('ðŸ”— Connected to MQTT broker');
      config.sources.mqtt.topics.forEach(topic => {
        mqttClient.subscribe(topic);
        console.log(`ðŸ“¡ Subscribed to: ${topic}`);
      });
    });

    // PostgreSQL Client
    const pgClient = new Client({
      host: config.sources.postgres.host,
      port: config.sources.postgres.port,
      database: config.sources.postgres.database,
      user: config.sources.postgres.user,
      password: config.sources.postgres.password
    });

    pgClient.connect().then(() => {
      console.log('ðŸ’¾ Connected to PostgreSQL');
    }).catch(err => {
      console.error('âŒ PostgreSQL connection error:', err);
    });

    // Message processing
    mqttClient.on('message', async (topic, message) => {
      try {
        const data = JSON.parse(message.toString());
        console.log(`ðŸ“Š Received: ${data.sensorId} = ${data.value}`);

        // Add to batch for AI processing
        messageBatch.push({
          ...data,
          receivedAt: moment().toISOString(),
          topic: topic
        });

        // Check if we should send to AI
        const shouldProcess = shouldSendToAI(data);
        if (shouldProcess || messageBatch.length >= config.ai.batchSize) {
          await processBatchToAI();
        }

      } catch (error) {
        console.error('âŒ Message processing error:', error);
      }
    });

    // Periodic batch processing
    setInterval(async () => {
      const timeSinceLastProcess = Date.now() - lastProcessTime;
      if (messageBatch.length > 0 && timeSinceLastProcess >= config.ai.intervalMs) {
        await processBatchToAI();
      }
    }, config.ai.intervalMs);

    function shouldSendToAI(data) {
      // Send critical sensor data immediately
      if (config.filters.criticalSensors.includes(data.sensorId)) {
        return true;
      }

      // Check for anomalies (simplified)
      if (data.sensorId === 'machine1' && data.value > 50) { // High temperature
        console.log('ðŸš¨ High temperature anomaly detected!');
        return true;
      }

      if (data.sensorId.includes('main') && data.value < 50) { // Low efficiency
        console.log('âš ï¸ Low efficiency detected!');
        return true;
      }

      return false;
    }

    async function processBatchToAI() {
      if (messageBatch.length === 0) return;

      try {
        console.log(`ðŸ§  Sending ${messageBatch.length} messages to AI processing...`);

        // Get recent historical context
        const context = await getHistoricalContext();

        // Prepare AI payload
        const aiPayload = {
          telemetryBatch: messageBatch,
          context: context,
          timestamp: moment().toISOString()
        };

        // Send to AI Function (mock for now since functions are still deploying)
        console.log('ðŸ“¤ AI Payload prepared:', {
          batchSize: messageBatch.length,
          contextDataPoints: context.length,
          timestamp: aiPayload.timestamp
        });

        // In production, this would send to Event Hub or directly call the Function
        // await sendToEventHub(aiPayload);
        // await callAIFunction(aiPayload);

        // Clear batch
        messageBatch = [];
        lastProcessTime = Date.now();

        console.log('âœ… Batch processed successfully');

      } catch (error) {
        console.error('âŒ AI processing error:', error);
        // Keep messages for retry
      }
    }

    async function getHistoricalContext() {
      try {
        const query = `
          SELECT sensor_id, AVG(value) as avg_value, COUNT(*) as count
          FROM sensor_data 
          WHERE timestamp > NOW() - INTERVAL '1 hour'
          GROUP BY sensor_id
          ORDER BY sensor_id
        `;
        
        const result = await pgClient.query(query);
        return result.rows;

      } catch (error) {
        console.error('âŒ Context query error:', error);
        return [];
      }
    }

    async function sendToEventHub(payload) {
      // Event Hub integration for production
      console.log('ðŸ“¡ Event Hub integration pending...');
    }

    async function callAIFunction(payload) {
      // Direct function call for immediate insights
      try {
        const response = await axios.post(`${config.ai.functionUrl}/api/factoryInsights`, {
          telemetryData: payload.telemetryBatch[0], // Send latest for immediate analysis
          question: "What insights can you provide about current factory operations?"
        }, {
          headers: {
            'Content-Type': 'application/json'
          }
        });

        console.log('ðŸ¤– AI Insight:', response.data.answer);

      } catch (error) {
        console.log('â³ AI Function not yet available:', error.message);
      }
    }

    // Graceful shutdown
    process.on('SIGTERM', () => {
      console.log('ðŸ”„ Shutting down AI bridge...');
      mqttClient.end();
      pgClient.end();
      process.exit(0);
    });

    console.log('ðŸŒ‰ AI Bridge initialized and running...');